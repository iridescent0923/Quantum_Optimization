{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Standard Library Imports\n",
    "# ==============================\n",
    "from enum import Enum\n",
    "import random\n",
    "\n",
    "# ==============================\n",
    "# Third-party Library Imports\n",
    "# ==============================\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Latex\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import numpy as np  # Original numpy\n",
    "import pennylane as qml\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Setup for Quantum Computations\n",
    "# ==============================\n",
    "\n",
    "# PennyLane settings\n",
    "dev = qml.device('default.mixed', wires=1)\n",
    "\n",
    "# Define Hamiltonian for quantum computations\n",
    "H = qml.Hamiltonian(coeffs = [-0.5], observables=[qml.PauliZ(0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Parameters\n",
    "Tau_global = torch.tensor(0)   # Dephase tau\n",
    "Gamma_ps_global = torch.tensor(0)\n",
    "Paras_global = torch.tensor([0, 0], dtype=torch.float)\n",
    "Phi_global = torch.tensor(0, dtype=torch.float)\n",
    "\n",
    "def Dephase_factor(tau):\n",
    "    \"\"\" Take tau and return gamma based on the following relation.\"\"\"\n",
    "    \n",
    "    return 1 - torch.exp(-2 * tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Let, e^{-t/T_2} = e^{-\\tau}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{1}{2} \n",
    "\n",
    "\\begin{bmatrix}\n",
    "\n",
    "1 & e^{(i\\phi - \\tau)} \\\\\n",
    "e^{(-i\\phi - \\tau)} & 1\n",
    "\n",
    "\\end{bmatrix}\n",
    "\n",
    "=\n",
    "\n",
    "\\frac{1}{2} \n",
    "\n",
    "\\begin{bmatrix}\n",
    "\n",
    "1 & e^{i\\phi} \\sqrt{1 - \\gamma} \\\\\n",
    "e^{-i\\phi} \\sqrt{1 - \\gamma} & 1\n",
    "\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$$\n",
    "\n",
    "Then,\n",
    "\\quad \\gamma = \n",
    "1 - e^{-2 \\tau}\n",
    "$$\n",
    "\n",
    "$$ \n",
    "e^{-\\tau} = \\sqrt{1 - \\gamma}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1160,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev, interface='torch', diff_method='backprop')\n",
    "def circuit(phi):\n",
    "    global Paras_global, Tau_global\n",
    "    theta_x = Paras_global[0]\n",
    "    phi_z = Paras_global[1]\n",
    "    \n",
    "    gamma_dephase = Dephase_factor(Tau_global)  \n",
    "\n",
    "    qml.RX(torch.pi/2, wires = 0)\n",
    "\n",
    "    qml.ApproxTimeEvolution(H, phi, 1)\n",
    "    qml.PhaseDamping(gamma_dephase, wires = 0) \n",
    "\n",
    "    qml.RZ(phi_z, wires = 0)  # phi_z\n",
    "    \n",
    "    qml.RX(theta_x, wires = 0)  # theta_x\n",
    "    \n",
    "    return qml.density_matrix(wires = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = qml.draw_mpl(circuit)(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1162,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev, interface='torch', diff_method='backprop')\n",
    "def Post_selection(phi):\n",
    "    \n",
    "    global Paras_global, Gamma_ps_global\n",
    "    \n",
    "    density_matrix = circuit(phi)\n",
    "    qml.QubitDensityMatrix(density_matrix, wires = 0)\n",
    "    \n",
    "    # Kraus operator for 2*2 matrix\n",
    "    K = torch.tensor([\n",
    "        [torch.sqrt(1 - Gamma_ps_global), 0],\n",
    "        [0, 1]\n",
    "    ], dtype=torch.complex128)\n",
    "    \n",
    "    Numerator = K @ density_matrix @ K.conj().T\n",
    "    Denominator = torch.trace(Numerator)\n",
    "    rho_ps = Numerator / Denominator\n",
    "\n",
    "    qml.QubitDensityMatrix(rho_ps, wires = 0)\n",
    "    \n",
    "    return qml.density_matrix(wires = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(paras):\n",
    "    \n",
    "    global Paras_global, Phi_global\n",
    "    Paras_global = paras\n",
    "\n",
    "    CFI = qml.qinfo.classical_fisher(circuit)(Phi_global)\n",
    "    \n",
    "    return -CFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_circuit(desired_tau_dephase, desired_gamma_post_selection):\n",
    "    global Tau_global, Gamma_ps_global \n",
    "    \n",
    "    Tau_global = torch.tensor(desired_tau_dephase)\n",
    "    Gamma_ps_global = torch.tensor(desired_gamma_post_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_optimization_result(sweep_range)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phi = torch.arange(0,to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def primative():\n",
    "    # device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "    # params_t = torch.tensor([np.pi/2, np.pi/3], requires_grad=True, device=device)\n",
    "    # params_t = torch.tensor(params, requires_grad=True, device=torch.device('mps'))\n",
    "\n",
    "    # params_t = params_t.detach().clone().requires_grad_(True)\n",
    "\n",
    "    # params_t = torch.tensor([np.pi/3, np.pi/3], requires_grad=True)\n",
    "\n",
    "    params_t = torch.tensor([1.0, torch.pi/2], requires_grad=True)\n",
    "\n",
    "    Circuit_select_global = Post_selection\n",
    "    Phi_global = torch.tensor([torch.pi*2])\n",
    "\n",
    "    # opt = torch.optim.LBFGS([params_t])\n",
    "    # opt = torch.optim.Adam([params_t])\n",
    "    opt = torch.optim.LBFGS(\n",
    "        [params_t], \n",
    "        lr=0.01,              # Learning rate\n",
    "        max_iter=20,          # Maximum number of iterations per optimization step\n",
    "        max_eval=None,        # Maximum number of function evaluations per optimization step\n",
    "        tolerance_grad=1e-7,  # Termination tolerance on the gradient norm\n",
    "        tolerance_change=1e-9,# Termination tolerance on the function value/parameter changes\n",
    "        history_size=100      # Update history size\n",
    "    )\n",
    "\n",
    "    steps = 500\n",
    "\n",
    "    f_logs = [cost_function(params_t).item()]\n",
    "    ftol = 1e-10\n",
    "\n",
    "    def closure():\n",
    "        opt.zero_grad()\n",
    "        loss = cost_function(params_t)\n",
    "        loss.backward()\n",
    "        return loss\n",
    "\n",
    "    for i in range(steps):\n",
    "        opt.step(closure)\n",
    "        fval = cost_function(opt.param_groups[0]['params'][0]).item()\n",
    "        print(f\"{i+1:03d}th iteration, CFI=\", fval)\n",
    "        f_logs.append(fval)\n",
    "        if np.abs((fval-f_logs[-2])/fval) < ftol:\n",
    "            break\n",
    "        \n",
    "    print(\"CFI=\", fval, \"Paras=\", opt.param_groups[0]['params'][0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_optimization(sweep_range, initial_parameters, method):\n",
    "    Phi = torch.arange(sweep_range[0], sweep_range[1], sweep_range[2], dtype=torch.float32)\n",
    "    Data = torch.zeros((len(Phi), len(initial_parameters) + 2))\n",
    "    Data[:,0] = Phi\n",
    "    \n",
    "    global Phi_global\n",
    "    params_tensor = initial_parameters.clone().requires_grad_(True)\n",
    "    \n",
    "    if method == 'LBFGS':\n",
    "        opt = torch.optim.LBFGS(\n",
    "                [params_tensor], \n",
    "                lr=0.01,              # Learning rate\n",
    "                max_iter=20,          # Maximum number of iterations per optimization step\n",
    "                max_eval=None,        # Maximum number of function evaluations per optimization step\n",
    "                tolerance_grad=1e-7,  # Termination tolerance on the gradient norm\n",
    "                tolerance_change=1e-9,# Termination tolerance on the function value/parameter changes\n",
    "                history_size=100      # Update history size\n",
    "        )\n",
    "    elif method == 'Adam':\n",
    "        opt = torch.optim.Adam(\n",
    "            [params_tensor]\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Invalid optimizer choice.\")\n",
    "    \n",
    "    def closure():\n",
    "        opt.zero_grad()\n",
    "        loss = cost_function(params_tensor)\n",
    "        loss.backward()\n",
    "        return loss\n",
    "       \n",
    "    steps = 500 \n",
    "    f_logs = [cost_function(params_tensor).item()]\n",
    "    ftol = 1e-10\n",
    "        \n",
    "    # Begin optimization\n",
    "    for phi_idx in range(len(Phi)):\n",
    "        Phi_global = Phi[phi_idx].clone().requires_grad_(True)\n",
    "\n",
    "        for i in range(steps):\n",
    "            opt.step(closure)\n",
    "\n",
    "            fval = cost_function(opt.param_groups[0]['params'][0]).item()\n",
    "            # print(f\"{i+1:03d}th iteration, CFI=\", fval)\n",
    "            f_logs.append(fval)\n",
    "            if np.abs((fval-f_logs[-2])/fval) < ftol:\n",
    "                break\n",
    "            \n",
    "        print(\"CFI =\", -fval, \"Paras =\", opt.param_groups[0]['params'][0].detach().numpy())\n",
    "        \n",
    "        Data[phi_idx, 1] = -fval\n",
    "        Data[phi_idx, 2:] = opt.param_groups[0]['params'][0]\n",
    "        \n",
    "        # torch.cat(([-fval], opt.param_groups[0]['params'][0].detach().numpy()))\n",
    "\n",
    "        \n",
    "    return Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CFI = 0.9999999439436149 Paras = [1.5706507 1.5707964]\n",
      "CFI = 1.0000000043387454 Paras = [1.5706773 1.5707964]\n",
      "CFI = 0.9999999613223961 Paras = [1.5706797 1.5707964]\n",
      "CFI = 0.9999999885892861 Paras = [1.570687  1.5707964]\n",
      "CFI = 0.9999998957656575 Paras = [1.5706992 1.5707964]\n",
      "CFI = 0.9999999609703611 Paras = [1.5707328 1.5707964]\n",
      "CFI = 1.0000000423778834 Paras = [1.570739  1.5707964]\n",
      "CFI = 0.9999999469501494 Paras = [1.5707496 1.5707964]\n",
      "CFI = 0.999999929573703 Paras = [1.5707717 1.5707964]\n",
      "CFI = 1.000000037035318 Paras = [1.5707848 1.5707964]\n",
      "CFI = 0.9999999810552949 Paras = [1.5707898 1.5707964]\n",
      "CFI = 1.0000001077479914 Paras = [1.5707918 1.5707964]\n",
      "CFI = 1.0000000105439304 Paras = [1.5707935 1.5707964]\n",
      "CFI = 0.9999999244817761 Paras = [1.5707947 1.5707964]\n",
      "CFI = 1.0000000074166646 Paras = [1.5707959 1.5707964]\n",
      "CFI = 0.9999999852434223 Paras = [1.5707967 1.5707964]\n",
      "CFI = 0.9999999737568889 Paras = [1.5707967 1.5707964]\n",
      "CFI = 0.9999999462351817 Paras = [1.5707967 1.5707964]\n",
      "CFI = 1.0000000262881767 Paras = [1.5707967 1.5707964]\n",
      "CFI = 1.0000000894664294 Paras = [1.5707967 1.5707964]\n",
      "CFI = 1.000000012317361 Paras = [1.5707967 1.5707964]\n",
      "CFI = 0.9999998526560757 Paras = [1.5707967 1.5707964]\n",
      "CFI = 1.000000014323516 Paras = [1.5707967 1.5707964]\n",
      "CFI = 1.000000100646232 Paras = [1.5707967 1.5707964]\n",
      "CFI = 0.9999999497921797 Paras = [1.5707967 1.5707964]\n",
      "CFI = 1.0000000658697903 Paras = [1.5707967 1.5707964]\n",
      "CFI = 1.0000000865694196 Paras = [1.5707967 1.5707964]\n",
      "CFI = 1.0000001543582107 Paras = [1.5707967 1.5707964]\n",
      "CFI = 0.9999999224190144 Paras = [1.5707967 1.5707964]\n",
      "CFI = 0.9999998802835479 Paras = [1.5707967 1.5707964]\n",
      "CFI = 1.0000000732758325 Paras = [1.5707967 1.5707964]\n",
      "CFI = 0.999999967637498 Paras = [1.5707967 1.5707964]\n"
     ]
    }
   ],
   "source": [
    "sweep_range = torch.tensor([0, 1*torch.pi, 1e-1], dtype=torch.float)\n",
    "init_par = torch.tensor([1, torch.pi/2], dtype=torch.float)\n",
    "result = torch_optimization(sweep_range, init_par, 'LBFGS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def torch_optimization(sweep_range, initial_parameters, method):\n",
    "#     Phi = torch.arange(sweep_range[0], sweep_range[1], sweep_range[2])\n",
    "#     Data = torch.tensor((len(Phi), len(initial_parameters) + 2))\n",
    "#     # Phi = np.arange(sweep_range[0], sweep_range[1], sweep_range[2])\n",
    "#     # Data = np.zeros((len(Phi), len(initial_parameters) + 2))\n",
    "#     Data[:,0] = Phi\n",
    "    \n",
    "#     global Phi_global\n",
    "    \n",
    "#     if method == 'LBFGS':\n",
    "#         opt = torch.optim.LBFGS(\n",
    "#                 [initial_parameters], \n",
    "#                 lr=0.01,              # Learning rate\n",
    "#                 max_iter=20,          # Maximum number of iterations per optimization step\n",
    "#                 max_eval=None,        # Maximum number of function evaluations per optimization step\n",
    "#                 tolerance_grad=1e-7,  # Termination tolerance on the gradient norm\n",
    "#                 tolerance_change=1e-9,# Termination tolerance on the function value/parameter changes\n",
    "#                 history_size=100      # Update history size\n",
    "#         )\n",
    "#     elif method == 'Adam':\n",
    "#         opt = torch.optim.Adam(\n",
    "#             [initial_parameters]\n",
    "#         )\n",
    "#     else:\n",
    "#         raise ValueError(\"Invalid optimizer choice.\")\n",
    "    \n",
    "#     def closure():\n",
    "#         opt.zero_grad()\n",
    "#         loss = cost_function(initial_parameters)\n",
    "#         loss.backward()\n",
    "#         return loss\n",
    "       \n",
    "#     steps = 500 \n",
    "#     f_logs = [cost_function(initial_parameters).item()]\n",
    "#     ftol = 1e-10\n",
    "        \n",
    "#     # Begin optimization\n",
    "#     for phi_idx in range(len(Phi)):\n",
    "#         Phi_global = torch.tensor(Phi[phi_idx])  \n",
    "\n",
    "#         for i in range(steps):\n",
    "#             opt.step(closure)\n",
    "\n",
    "#             fval = cost_function(opt.param_groups[0]['params'][0]).item()\n",
    "#             # print(f\"{i+1:03d}th iteration, CFI=\", fval)\n",
    "#             f_logs.append(fval)\n",
    "#             if np.abs((fval-f_logs[-2])/fval) < ftol:\n",
    "#                 break\n",
    "            \n",
    "#         print(\"CFI =\", -fval, \"Paras =\", opt.param_groups[0]['params'][0].detach().numpy())\n",
    "        \n",
    "#         Data[phi_idx, 1] = -fval\n",
    "#         Data[phi_idx, 2:] = opt.param_groups[0]['params'][0]\n",
    "#         # Data[phi_idx, 1] = -fval\n",
    "#         # Data[phi_idx, 2:] = opt.param_groups[0]['params'][0].detach().numpy()\n",
    "\n",
    "        \n",
    "#     return Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set_circuit(0, 0)\n",
    "# sweep_range = torch.tensor([0, 1*torch.pi, 1e-1], dtype=torch.float)\n",
    "# init_par = torch.tensor([1, torch.pi/2], dtype=torch.float, requires_grad=True)\n",
    "# result = torch_optimization(sweep_range, init_par, 'LBFGS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 1.0000, 1.5707, 1.5708],\n",
       "        [0.1000, 1.0000, 1.5707, 1.5708],\n",
       "        [0.2000, 1.0000, 1.5707, 1.5708],\n",
       "        [0.3000, 1.0000, 1.5707, 1.5708],\n",
       "        [0.4000, 1.0000, 1.5707, 1.5708],\n",
       "        [0.5000, 1.0000, 1.5707, 1.5708],\n",
       "        [0.6000, 1.0000, 1.5707, 1.5708],\n",
       "        [0.7000, 1.0000, 1.5707, 1.5708],\n",
       "        [0.8000, 1.0000, 1.5708, 1.5708],\n",
       "        [0.9000, 1.0000, 1.5708, 1.5708],\n",
       "        [1.0000, 1.0000, 1.5708, 1.5708],\n",
       "        [1.1000, 1.0000, 1.5708, 1.5708],\n",
       "        [1.2000, 1.0000, 1.5708, 1.5708],\n",
       "        [1.3000, 1.0000, 1.5708, 1.5708],\n",
       "        [1.4000, 1.0000, 1.5708, 1.5708],\n",
       "        [1.5000, 1.0000, 1.5708, 1.5708],\n",
       "        [1.6000, 1.0000, 1.5708, 1.5708],\n",
       "        [1.7000, 1.0000, 1.5708, 1.5708],\n",
       "        [1.8000, 1.0000, 1.5708, 1.5708],\n",
       "        [1.9000, 1.0000, 1.5708, 1.5708],\n",
       "        [2.0000, 1.0000, 1.5708, 1.5708],\n",
       "        [2.1000, 1.0000, 1.5708, 1.5708],\n",
       "        [2.2000, 1.0000, 1.5708, 1.5708],\n",
       "        [2.3000, 1.0000, 1.5708, 1.5708],\n",
       "        [2.4000, 1.0000, 1.5708, 1.5708],\n",
       "        [2.5000, 1.0000, 1.5708, 1.5708],\n",
       "        [2.6000, 1.0000, 1.5708, 1.5708],\n",
       "        [2.7000, 1.0000, 1.5708, 1.5708],\n",
       "        [2.8000, 1.0000, 1.5708, 1.5708],\n",
       "        [2.9000, 1.0000, 1.5708, 1.5708],\n",
       "        [3.0000, 1.0000, 1.5708, 1.5708],\n",
       "        [3.1000, 1.0000, 1.5708, 1.5708]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 1172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n",
      "True\n",
      "True\n",
      "macOS-14.1-arm64-arm-64bit\n"
     ]
    }
   ],
   "source": [
    "print (torch.__version__) \n",
    "print(torch.backends.mps.is_built()) \n",
    "print(torch.backends.mps.is_available())\n",
    "!python -c 'import platform;print(platform.platform())'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
